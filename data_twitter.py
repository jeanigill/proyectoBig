# -*- coding: utf-8 -*-
"""Data-Twitter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vvmZqW-skh3JoMZfVAPBKTusY2FT9q28

# COMPONENTE 1 : Data Fetching

Importar librerias
"""

#Instalación de paquetes
!pip install config
!pip install langdetect

#Importacion de librerias 
import tweepy
import datetime
import pandas as pd

#Utilizar las Credeciales de Twitter 
TWITTER_CONSUMER_KEY = 'XabZgmY0CvdnC80CIqukoEq5G'
TWITTER_CONSUMER_SECRET = 'SfZ95BhHw5zSQhqzbCF89lHC0GRNpzS15Zx0XK1dzsDXHsiTYj'
TWITTER_ACCESS_TOKEN = '1389193434909532160-92Xm44NHeBlFPjPb7EdQZ6TMIPDYs2'
TWITTER_ACCESS_TOKEN_SECRET= '4RhM83yaMr0wFFSzhCxH3IphaBsInhGkLLhYmg3M8kXej'

auth = tweepy.OAuthHandler(TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET)
auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)
api = tweepy.API(auth,wait_on_rate_limit=True)

#Delimitar fechas entre hoy y ayer
today = datetime.date.today()
yesterday= today - datetime.timedelta(days=1)

tweets_list = tweepy.Cursor(api.search, q="#BTSMeal since:" + str(yesterday)+ " until:" + str(today),tweet_mode='extended', lang='en').items(600)

tweets_list

output = []
for tweet in tweets_list:
    text = tweet._json["full_text"]
    print(text)
    username = tweet.user.name
    location = tweet.user.location
    created_at = tweet.created_at
    favourite_count = tweet.favorite_count
    retweet_count = tweet.retweet_count
    source = tweet.source
  
    
    line = {'Text' : text, 'User' : username, 'Location' : location, 'Created' : created_at ,'Favourite_count' : favourite_count, 'Retweet_count' : retweet_count, 'Source' : source}
    output.append(line)

#Crear DataFrame y guardar como archivo cvs
df = pd.DataFrame(output)
df.loc[df['Location'] == '', 'Location'] = 'No tiene'
df.to_csv('data.csv', index = False, sep = ';')

df.head(10)



import matplotlib.pyplot as plt
import seaborn as sns

#data = df.groupby('Source')
#data_x = df.iloc[:, [2]])
#fig = plt.figure(dpi=100, figsize=(10,5))
#ax = fig.gca()
#sns.barplot( ax=ax, orient="h")
#ax.set_ylabel("Card name")
#ax.set_xlabel("Occurrences")
#ax.set_title("Most used cards across Yu-Gi-Oh! decks")

"""# Componente 2.1
En esta sección del componente 2 comparamos los resultados obtenidos con dos algoritmos diferentes:

*   Vader
*   TextBlob



Un indicador que elegimos para elegir el algoritmo es fijarnos en la distribución de los sentimientos (porcentualmente). Es decir, mientras menos se concentre análisis en uno ó dos sentimientos, mejor.
"""

#IMPORT LIB
import nltk
nltk.download('vader_lexicon')
import re
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from textblob import TextBlob

#Sentimen analysis using vader algorithm
tweets_vader = []
positive_list = []
negative_list = []
neutral_list = []
negative = 0
positive = 0
neutral = 0
tweets_list2 = tweepy.Cursor(api.search, q="#BTSMeal since:" + str(yesterday)+ " until:" + str(today),tweet_mode='extended', lang='es').items(600)
for tweet in tweets_list2:
  tweets_vader.append(tweet._json["full_text"])
  score = SentimentIntensityAnalyzer().polarity_scores(tweet._json["full_text"])
  neg = score['neg']
  pos = score['pos']
  neu = score['neu']
  comp = score['compound']
  
  if neg > pos:
    negative_list.append(tweet._json["full_text"])
    negative +=1

  if pos > neg:
    positive_list.append(tweet._json["full_text"])
    positive +=1

  if pos == neg:
    neutral_list.append(tweet._json["full_text"])
    neutral +=1

#Calcular porcentaje
def calcularPorc(num, entero):
  return 100*float(num)/float(entero)

#Calcular porcentaje usando el algoritmo vader
positive = round(calcularPorc(positive, len(tweets_vader)))
negative = round(calcularPorc(negative, len(tweets_vader)))
neutral = round(calcularPorc(neutral, len(tweets_vader)))

#Crear DataFrame para analizar con TextBlob
tweets = pd.DataFrame(df['Text'])
tweets = tweets.rename(columns={'text': 'Tweets'})

# crear la funcion para obtener la subjectividad con la librería TextBlob
def getSubjectivity(text):
   return TextBlob(text).sentiment.subjectivity

# Crear la funcion para obtener la polaridad
def getPolarity(text):
   return  TextBlob(text).sentiment.polarity


# Crear dos nuevas columnas 'Subjectividad' & 'Polaridad'
tweets['Subjectividad'] = tweets['Text'].apply(getSubjectivity)
tweets['Polaridad'] = tweets['Text'].apply(getPolarity)

#mostrar dataFrame
tweets.head(10)

# Crear una funcion para calcular negativo (-1), neutral (0) and positivo (+1) 
def getAnalysis(score):
  if score < 0:
    return 'Negativo'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positivo'

tweets['Analisis'] = tweets['Polaridad'].apply(getAnalysis)
# Show the dataframe
tweets

#Guardar en distintos df según sentimiento y calcular porcentaje de sentimientos
#Tweets positivos
pos_tweets = tweets[tweets.Analisis == 'Positivo']
pos_tweets = pos_tweets['Text']

positivo = round( (pos_tweets.shape[0] / tweets.shape[0]) * 100, 1)
print(positivo)

#Tweetss negativos
neg_tweets = tweets[tweets.Analisis == 'Negativo']
neg_tweets = neg_tweets['Text']

negativo = round( (neg_tweets.shape[0] / tweets.shape[0]) * 100, 1)
print(negativo)

#Tweets neutrales
neu_tweets = tweets[tweets.Analisis == 'Neutral']
neu_tweets = neu_tweets['Text']

neutro = round( (neu_tweets.shape[0] / tweets.shape[0]) * 100, 1)
print(neutro)

#Imprimimos los resultados obtenidos con ambos algoritmos para comparar.
#Un indicador clave para nosotras es que los sentimientos estén más distribuidos en los tres sentimientos
print("Resultados con Vader (inglés)")
print('Porcentaje de tweets positivos: '+str(positive)+"%")
print("Porcentaje de tweets negativos: "+str(negative)+"%")
print("Porcentaje de tweets neutros: "+str(neutral)+"%")
print("")
print("Resultados con TextBlob (inglés)")
print('Porcentaje de tweets positivos: '+str(positivo)+"%")
print("Porcentaje de tweets negativos: "+str(negativo)+"%")
print("Porcentaje de tweets neutros: "+str(neutro)+"%")

"""# Componente 2.2 
En esta sección, tras elegir el algoritmo a utilizar (TextBlob conforme a los resultados obtenidos en Componente 2.1), realizamos una limpieza de datos, y luego graficamos de distintas formas para poder ver los resultados obtenidos de nuestro Sentiment Analysis.
"""

#Importar librerías
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from PIL import Image
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
import nltk
nltk.download('vader_lexicon')
!pip install emoji
#emojis
import emoji
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

#Limpiar los tweets
def cleanTweets(tweet):
  tweet = re.sub(r'^https?:\/\/.*[\r\n]*', '', tweet, flags=re.MULTILINE) #remove links
  tweet = re.sub('@[A-Za-z0-9]+', '', tweet) #remove mentions
  tweet = re.sub(':', '', tweet) #remove mentions
  tweet = re.sub('#', '', tweet) #remove hashtags
  tweet = re.sub('RT[\s]+', '', tweet) #remove RT
  tweet = re.sub(emoji.get_emoji_regexp(), r"", tweet) #remove emojis
  tweet = re.sub('@\S+|#\S+|htt\S+', '', tweet) #remove
  return tweet

#Ejecutar función
tweets['Text'] = df['Text'].apply(cleanTweets)

#DataFrame limpio
tweets

#Crear DataFrame y guardar como archivo cvs
tweets = pd.DataFrame(output)
tweets.to_csv('analisis-TW.csv', index = False, sep = ';')

#Guardar en los DataFrames los tweets limpios
#Tweets positivos
pos_tweets = tweets[tweets.Analisis == 'Positivo']
pos_tweets = pos_tweets['Text']

#Tweetss negativos
neg_tweets = tweets[tweets.Analisis == 'Negativo']
neg_tweets = neg_tweets['Text']

#Tweets neutrales
neu_tweets = tweets[tweets.Analisis == 'Neutral']
neu_tweets = neu_tweets['Text']

#Imprimir tweets positivos
pos_tweets.head()

#Imprimir tweets negativos
neg_tweets.head(20)

#Imprimir tweets neutrales
neu_tweets.head(20)

#Promedio de polaridad para cada sentimiento
tweets.groupby('Analisis').agg({
    'Polaridad' : 'mean'
})

#Gráfico nube de palabras con todos los tweets
text = open('data.csv', 'r').read()
text = ' '.join(tweet for tweet in tweets['Text'])
stopwords.words('english')  #texto en inglés
stopwords = set(stopwords.words('english')) #setear la variable con los stopwords
#stopwords = nltk.corpus.stopwords.words('spanish')  #en el caso de utilizar texto en español
#custom_mask = np.array(Image.open('Twitter-Logo.png')) 
wc = WordCloud(background_color = 'white',
               stopwords = stopwords,
#              mask = custom_mask,
               contour_width = 3,
               contour_color = 'black')

wc.generate(text)
#image_colors = ImageColorGenerator(custom_mask)
#wc.recolor(color_func = image_colors)

#Plotting
plt.figure(figsize=[20,10])
plt.imshow(wc, interpolation = 'bilinear')
plt.axis('off')
plt.show()

# Histograma de los distintos sentimientos
#Comparar los sentimientos en cantidades de tweets
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
tweets['Analisis'].value_counts().plot(kind = 'bar')

plt.show()
print(" Los datos están representados en cantidad de tweets")

#Graficar un pie chart (para ver los porcentajes de los sentimientos)
#Comparar los sentimientos de forma porcentual
sentiments = 'Positivo', 'Negativo', 'Neutro'
values = positivo, negativo, neutro
colors = ['gold', 'yellowgreen', 'lightcoral']
explode = (0.1, 0.1, 0.1) #para que salga partidito

#Plot
plt.pie(values, explode = explode, labels = sentiments, colors = colors, autopct = '%1.1f%%', shadow=True, startangle=140)

plt.axis('equal')
plt.show

#WORDCLOUD POSITIVO
text = open('data.csv', 'r').read()
text = ' '.join(tweet for tweet in pos_tweets)
#custom_mask = np.array(Image.open('Twitter-Logo.png')) 
wc = WordCloud(background_color = 'white',
               stopwords = stopwords,
#               mask = custom_mask,
               contour_width = 3,
               contour_color = 'black')

wc.generate(text)
#image_colors = ImageColorGenerator(custom_mask)
#wc.recolor(color_func = image_colors)

#Plotting
plt.figure(figsize=[20,10])
plt.imshow(wc, interpolation = 'bilinear')
plt.axis('off')
plt.show()

#WORDCLOUD NEGATIVO
text = open('data.csv', 'r').read()
text = ' '.join(tweet for tweet in neg_tweets)
#custom_mask = np.array(Image.open('Twitter-Logo.png')) 
wc = WordCloud(background_color = 'white',
               stopwords = stopwords,
#               mask = custom_mask,
               contour_width = 3,
               contour_color = 'black')

wc.generate(text)
#image_colors = ImageColorGenerator(custom_mask)
#wc.recolor(color_func = image_colors)

#Plotting
plt.figure(figsize=[20,10])
plt.imshow(wc, interpolation = 'bilinear')
plt.axis('off')
plt.show()

#WORDCLOUD NEUTROS
text = open('data.csv', 'r').read()
text = ' '.join(tweet for tweet in neu_tweets)
#custom_mask = np.array(Image.open('Twitter-Logo.png')) 
wc = WordCloud(background_color = 'white',
               stopwords = stopwords,
#               mask = custom_mask,
               contour_width = 3,
               contour_color = 'black')

wc.generate(text)
#image_colors = ImageColorGenerator(custom_mask)
#wc.recolor(color_func = image_colors)

#Plotting
plt.figure(figsize=[20,10])
plt.imshow(wc, interpolation = 'bilinear')
plt.axis('off')
plt.show()